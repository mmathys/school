% ------------------------------------------------------------------------------------------------ %
% SCHÄTZER
% ------------------------------------------------------------------------------------------------ %


\section{Schätzer}

Für eine Stichprobe $X_1, \ldots, X_n$ soll ein passendes Modell gefunden werden. Die Parameter $\theta = (\theta_1, \ldots,\theta_m)$ des Modells versucht man mit einem \emph{Schätzer} $T = (T_1,\ldots,T_m)$ aufgrund der Stichprobe herauszufinden. Die Schätzer sind Zufallsvariablen der Form $T_j = t_j(X_1,\ldots,X_n)$ für eine geeignete Funktion $t_j:\R^n\rightarrow\R$. Durch Einsetzen von Daten $x_i$ erhält man \emph{Schätzwertwerte} $t_j(x_1,\ldots,x_n)$ für $\theta_j$.


\begin{definition}[Erwartungstreu]
Ein Schätzer $T$ heisst \emph{erwartungstreu} für $\theta$, falls $\E[T] = \theta$ (im Mittel wird richtig geschätzt).
\end{definition}

\begin{definition}[Konsistent]
Eine Folge von Schätzern $T^{(n)}, n\in\mathbb{N}$ heisst \emph{konsistent} für $\theta$, falls $T^{(n)}$ für $n \rightarrow \infty$ im Modell $\mathbb{P_\theta}$ gegen $\theta$ konvergiert. Das heisst für jedes $\theta \in \Theta$ und $\epsilon > 0$ gilt
$$
\lim_{n\rightarrow\infty} \mathbb{P}[\,\abs{T^{(n)}-\theta}>\epsilon\,] = 0.
$$
\end{definition}

\begin{note}
Der Grundraum $\Omega$ und die Menge der beobachtbaren Ereignisse $\mathcal{F}$ sind fest. Die Wahl des Parameters $\theta$ aus dem Parameterraum $\Theta$ hat aber Einfluss auf das Wahrscheinlichkeitsmass $\P_\theta$. Mit $\E_\theta$ wird der Erwartungswert unter $\P_\theta$ bezeichnet.
\end{note}


% ------------------------------------------------------------------------------------------------ %
% MOMENTEN METHODE
% ------------------------------------------------------------------------------------------------ %


\subsection{Momenten-Methode}

\begin{definition}[Moment]
Das \emph{$k$-te Moment} einer Zufallsvariablen $X$ im Model $\P_\theta$ ist
$$
\mu_k := \mu_k(\theta) := \E_\theta[X^k].
$$
\end{definition}

\begin{definition}[Stichprobenmoment]
Das \emph{$k$-te Stichprobenmoment} von Zufallsvarialben $X_1,\ldots,X_n$ ist
$$
\hat\mu_k := \frac{1}{n} \sum_{i=1}^n X_i^k.
$$
\end{definition}

Die Parameter $\theta_i$ der theoretischen Verteilung werden als Funktion der Momente $\mu_k$ angegeben.
$$
\theta_j = g_j (\mu_1,\ldots,\mu_m)
\quad\text{für }j \in \{1,\ldots,m\}
$$
Den \emph{Momentenschätzer} für $\theta = (\theta_1,\ldots,\theta_m)$ erhält man, indem man die Stichprobenmomente in die Funktionen der Momente einsetzt; der Schätzer ist also $T 
= (T_1,\ldots,T_m)$ mit
$$
T_j := g_j(\hat\mu_1,\ldots,\hat\mu_m)
\quad\text{für }j \in \{1,\ldots,m\}
$$

\begin{example}
Gegeben seien $n$ unabhängige Realisierungen $x_1,\ldots,x_n$ einer Zufallsvariablen $X \sim \mathcal{P}(\lambda)$. Es gilt $\E[X] = \lambda$. Für die Funktion $g_1$ kann also die Idendität gewählt werden. Der Momentenschätzer ist somit
$$
\lambda_\text{MM} = \hat\mu_1 = \frac{1}{n} \sum_{i=1}^n x_i = \overline{x}.
$$
Es gilt aber auch $\var[X] = \E[X^2]-\E[X]^2 = \lambda$. Es kann also auch $g_1(\mu_1,\mu_2) = \mu_2-\mu_1^2$ gewählt werden. Dadurch erhält man einen anderen Momentenschätzer
$$
\lambda_\text{MM} =
\left(\frac{1}{n} \sum_{i=1}^n x_i^2\right) - \left(\sum_{i=1}^n x_i\right)^2 =
\frac{1}{n} \sum_{i=1}^n (x_i - \overline{x})^2
$$
\end{example}


% ------------------------------------------------------------------------------------------------ %
% MAXIMUM LIKELIHOOD
% ------------------------------------------------------------------------------------------------ %


\subsection{Maximum-Likelihood}

Es wird von einer Zufallsvariable $X_1,\ldots,X_n$ ausgegangen, deren gemeinsame Dichte $f(t_1,\ldots,t_n \mid \theta)$ von einem Parameter $\theta$ abhängt.
Die \emph{Likelihood-Funktion} $\mathcal{L}$ ist gegeben durch
$$
\mathcal{L}(x_1,\ldots,x_n \mid \theta) =
f(x_1,\ldots,x_n \mid \theta).
$$
Anschaulich ist das die Wahrscheinlichkeit\footnote{oder zumindest das stetige Pendant zur Wahrscheinlichkeit.}, dass im Modell $\P_\theta$ die Stichprobe $X_1,\ldots,X_n$ die Werte $x_1,\ldots,x_n$ liefert.
Um eine möglichst gute Anpassung des Modells an die Daten zu erreichen, wird der Likelihood-Schätzer als Funktion von $\theta$ maximiert.

\begin{note}
Im diskreten Fall wird lediglich die Dichte $f$ durch die Gewichtsfunktion $p$ ersetzt.
\end{note}

Oft sind die Zufallsvariablen $X_i$ unter $\P_\theta$ i.i.d. mit Dichtefunktion $f(t \mid \theta)$, so dass sich die Likelihood-Funktion vereinfacht zu
$$
\mathcal{L}(x_1,\ldots,x_n \mid \theta) =
\prod_{i=1}^n f(x_i \mid \theta).
$$
Aufgrund der Monotonie des Logarithmus kann dann die logarithmierte Likelihood-Funktion verwendet werden, ohne dass sich dadurch das Maximum der Funktion verschiebt.
$$
\log \mathcal{L}(x_1,\ldots,x_n \mid \theta) =
\sum_{i=1}^n \log f(x_i \mid \theta)
$$


\begin{example}
Gegeben seien $n$ unabhängige Realisierungen  $x_1,\ldots,x_n$ einer Zufallsvariable $X \sim Exp(\lambda)$ mit Dichte
$f(t) = \lambda e^{-\lambda t} \mathbb{1}_{[0,\infty)}(t)$ und unbekanntem Parameter $\lambda$.
Für die Likelihood-Funktion erhält man
$$
\mathcal{L}(\lambda) := \mathcal{L}(x_1,\ldots,x_n \mid \lambda) =
\prod_{i=1}^n \lambda e^{-\lambda x_i}
$$
und durch logarithmieren
$$
\log\mathcal{L}(\lambda) =
\sum_{i=1}^n \log \lambda e^{-\lambda x_i} =
n \log \lambda - \lambda \sum_{i=1}^n x_i.
$$
Zur Bestimmung des Maximums wird die Ableitung nullgesetzt:
$$
\frac{\d}{\d\lambda}\log\mathcal{L}(\lambda) =
\frac{n}{\lambda} - \sum_{i=1}^n x_i \overset{!}{=} 0
\quad\Rightarrow\quad
\lambda_\text{LH} = \frac{n}{\sum_{i=1}^n x_i}
$$
Aus $\frac{\d^2}{\d\lambda^2} \mathcal{L}(\lambda) = -\frac{n}{\lambda^2} < 0$ für $\lambda > 0$ folgt, dass es sich auch tatsächlich um ein Maximum handelt.
\end{example}


% ------------------------------------------------------------------------------------------------ %